{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Java Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !pip install javalang\n",
    "# !gcc -shared -o kotlin.so -fPIC src/parser.c\n",
    "project_path = \"Project Address\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import javalang\n",
    "\n",
    "class JavaCodeAnalyzer:\n",
    "    def __init__(self, project_path):\n",
    "        self.project_path = project_path\n",
    "        self.files = self.get_source_files()\n",
    "\n",
    "    def get_source_files(self):\n",
    "        \"\"\"Find all Java and Kotlin files in the project.\"\"\"\n",
    "        source_files = []\n",
    "        \n",
    "        for root, _, files in os.walk(self.project_path):\n",
    "            print(f\"Checking folder: {root}\")  # üîç Debugging line\n",
    "            \n",
    "            # ‚úÖ Ignore unnecessary folders\n",
    "            if \"target\" in root or \".mvn\" in root or \"test\" in root or \".git\" in root or \".idea\" in root:\n",
    "                print(f\"Skipping: {root}\")  # üîç Debugging line\n",
    "                continue  \n",
    "\n",
    "            for file in files:\n",
    "                if file.endswith(\".java\") or file.endswith(\".kt\"):  # ‚úÖ Now includes Kotlin\n",
    "                    source_files.append(os.path.join(root, file))\n",
    "\n",
    "        print(f\"Found {len(source_files)} source files:\")\n",
    "        for file in source_files:\n",
    "            print(file)\n",
    "\n",
    "        return source_files\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def extract_code_structure(self, file_path):\n",
    "        \"\"\"Extracts classes, methods, and key statements from Java code.\"\"\"\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            code = f.read()\n",
    "        \n",
    "        tree = javalang.parse.parse(code)\n",
    "        classes = []\n",
    "        methods = []\n",
    "        api_endpoints = []\n",
    "\n",
    "        for path, node in tree.filter(javalang.tree.ClassDeclaration):\n",
    "            classes.append(node.name)\n",
    "\n",
    "        for path, node in tree.filter(javalang.tree.MethodDeclaration):\n",
    "            methods.append(f\"{node.name}()\")\n",
    "        \n",
    "            # Detect API endpoints in Spring Boot applications\n",
    "            for annotation in node.annotations:\n",
    "                if annotation.name in [\"GetMapping\", \"PostMapping\", \"RequestMapping\"]:\n",
    "                    api_endpoints.append(annotation.element)\n",
    "\n",
    "        return {\n",
    "            \"file\": file_path,\n",
    "            \"classes\": classes,\n",
    "            \"methods\": methods,\n",
    "            \"api_endpoints\": api_endpoints\n",
    "        }\n",
    "    \n",
    "    def analyze_project(self):\n",
    "        analysis_results = []\n",
    "        for file in self.files:\n",
    "            analysis_results.append(self.extract_code_structure(file))\n",
    "        return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "\n",
    "# Load Kotlin grammar\n",
    "# KOTLIN_LANGUAGE = Language('tree-sitter-kotlin/kotlin.so', 'kotlin')\n",
    "\n",
    "def extract_code_structure(file_path):\n",
    "    \"\"\"Extracts classes and functions from a Kotlin file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            code = f.read()\n",
    "\n",
    "        parser = Parser()\n",
    "        parser.set_language(KOTLIN_LANGUAGE)\n",
    "        tree = parser.parse(code.encode(\"utf8\"))\n",
    "        root_node = tree.root_node\n",
    "\n",
    "        classes = []\n",
    "        functions = []\n",
    "\n",
    "        # Traverse the AST to find class and function definitions\n",
    "        def traverse(node):\n",
    "            if node.type == \"class_declaration\":\n",
    "                classes.append(node.child_by_field_name(\"name\").text.decode(\"utf8\"))\n",
    "            elif node.type == \"function_declaration\":\n",
    "                functions.append(node.child_by_field_name(\"name\").text.decode(\"utf8\"))\n",
    "\n",
    "            for child in node.children:\n",
    "                traverse(child)\n",
    "\n",
    "        traverse(root_node)\n",
    "\n",
    "        return {\"file\": file_path, \"classes\": classes, \"functions\": functions}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return {\"file\": file_path, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class CodeSummarizer:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "    def summarize_code(self, code_structure):\n",
    "        \"\"\"Generate a summary explaining the purpose of a class or method.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are analyzing a Java project. Based on the following code structure, explain its purpose in simple terms:\n",
    "        - Classes: {', '.join(code_structure['classes'])}\n",
    "        - Methods: {', '.join(code_structure['methods'])}\n",
    "        - API Endpoints: {', '.join(code_structure['api_endpoints'])}\n",
    "\n",
    "        Give a high-level overview of what this file is doing.\n",
    "        \"\"\"\n",
    "        return self.llm.predict(prompt)\n",
    "\n",
    "    def summarize_whole_project(self, project_structure):\n",
    "        \"\"\"Generate a high-level summary of the project.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Given the following extracted structure from a Java project, summarize its purpose:\n",
    "\n",
    "        {project_structure}\n",
    "\n",
    "        Try to infer if it's a web application, CLI tool, or something else.\n",
    "        \"\"\"\n",
    "        return self.llm.predict(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "class ProjectKnowledgeBase:\n",
    "    def __init__(self):\n",
    "        self.vector_db = Chroma(collection_name=\"code_insights\", embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "    def store_code_summary(self, file_summary, file_path):\n",
    "        self.vector_db.add_texts([file_summary], metadatas=[{\"source\": file_path, \"type\": \"code_summary\"}])\n",
    "\n",
    "    def store_project_summary(self, project_summary):\n",
    "        self.vector_db.add_texts([project_summary], metadatas=[{\"type\": \"project_summary\"}])\n",
    "\n",
    "    def query_summary(self, query):\n",
    "        return self.vector_db.similarity_search(query, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class CodeQueryEngine:\n",
    "    def __init__(self, knowledge_base):\n",
    "        self.qa_system = RetrievalQA.from_chain_type(llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0), retriever=knowledge_base.vector_db.as_retriever())\n",
    "\n",
    "    def ask(self, query):\n",
    "        return self.qa_system.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute project\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Step 1: Extract Code Structure\n",
    "    analyzer = JavaCodeAnalyzer(project_path)\n",
    "    code_structure = analyzer.analyze_project()\n",
    "\n",
    "    # Step 2: Summarize Each File\n",
    "    summarizer = CodeSummarizer()\n",
    "    kb = ProjectKnowledgeBase()\n",
    "\n",
    "    for file_data in code_structure:\n",
    "        summary = summarizer.summarize_code(file_data)\n",
    "\n",
    "        if not isinstance(summary, str):\n",
    "            summary = str(summary)  # Convert to string\n",
    "\n",
    "        kb.store_code_summary(summary, file_data['file'])\n",
    "\n",
    "    # Step 3: Generate a High-Level Summary\n",
    "    project_summary = summarizer.summarize_whole_project(code_structure)\n",
    "    kb.store_project_summary(project_summary)\n",
    "\n",
    "    # Step 4: Ask Questions\n",
    "    query_engine = CodeQueryEngine(kb)\n",
    "    print(query_engine.ask(\"What is the main goal of this project?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
